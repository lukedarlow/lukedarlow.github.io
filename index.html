<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Luke Darlow, PhD.</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>
					<h1 id="logo"><a href="#">Luke Darlow</a></h1>
					<p>AI Research Scientist.<br />
					Intelligence inspired from the ground up.</p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#one" class="active">About Me</a></li>
						<li><a href="#two">Featured Research</a></li>
						<li><a href="#three">Research Themes</a></li>
						<li><a href="#four">Contact</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<li><a href="https://scholar.google.com/citations?user=qxgq8n8AAAAJ" class="icon brands fa-google"><span class="label">Google Scholar</span></a></li>
						<li><a href="https://www.linkedin.com/in/luke-darlow-6457a0150/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/lukedarlow" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="https://x.com/LearningLukeD" class="icon brands fa-twitter"><span class="label">X</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="image main" data-position="center">
									<img src="images/banner.jpg" alt="" />
								</div>
								<div class="container">
									<header class="major">
										<h2>Luke Darlow</h2>
									</header>
									<p>
										I am an Artificial Ingelligence Research Scientist at <strong><a href="https://sakana.ai" target="_blank">Sakana AI</a></strong> in Tokyo, where I am focused on building the future of artificial intelligence by creating biologically-inspired models that leverage and emulate core aspects of true intelligence. Originally from South Africa, I have spent most of my life learning and researching. My  <strong><a href="https://pub.sakana.ai/ctm/" target="_blank">current research</a></strong> has resulted in a new kind of neural network, called the Continuous Thought Machine. My doctoral research focused on representation learning in complex unsupervised settings where neural networks often fail to generalize.
									</p>
									
									<a href="assets/Luke N Darlow - CV.pdf" class="button">Download Full CV</a>
								</div>
							</section>

						<!-- Two -->
							<section id="two">
								<div class="container">
									<header class="major">
										<h2>Featured Research</h2>
										<h3>Continuous Thought Machines</h3>
									</header>
									<img src="images/brain.png" alt="The CTM: a model that uses time as a tool" style="width:100%; max-width:600px; display:block; margin:auto;"/>
									<p style="margin-top:1em;">
										The <strong>Continuous Thought Machine (CTM)</strong> is a novel neural network architecture designed to explicitly incorporate neural timing, the consequential dynamics, and overall neural synchronization as foundational modelling elements. By moving beyond static neuron abstractions while remaining in the gamut of tractable deep learning implementations, the CTM can perform tasks requiring complex sequential reasoning and adaptive computation, where it can "think" longer for more challenging problems. This architecture is built on two core innovations:
									</p>
									<ul>
										<li><strong>Neuron-Level Temporal Processing:</strong> Each neuron uses its own unique weight parameters to process a history of incoming signals, allowing for the emergence of complex, dynamic neural activity.</li>
										<li><strong>Neural Synchronization as a Latent Representation:</strong> The model uses the synchronization of neural activity over time as the direct representation for observing the world and producing outputs, a biologically-inspired design choice that enables a new depth of computational capacity.</li>
									</ul>
									<p>This work represents a significant step toward more biologically plausible and powerful AI systems.</p>
									<a href="https://arxiv.org/abs/2505.05522" class="button primary">Read The Paper</a>
									<a href="https://pub.sakana.ai/ctm/" class="button">Project Page</a>
									<a href="https://github.com/SakanaAI/continuous-thought-machines" class="button">View Code</a>
								</div>
							</section>
						<!-- Three -->
							<section id="three">
								<div class="container">
									<header class="major">
										<h2>Other Research Themes</h2>
									</header>
									
									<div class="project-item">
										<h4>Foundational Models for Time Series Forecasting</h4>
										<p>During my time at the Systems Infrastructure Lab of Huawei, I designed and developed a foundational forecasting model, <strong><a href="https://arxiv.org/abs/2407.17880" target="_blank">DAM</a></strong>, which was the first of its kind to be presented at a high-level conference (ICLR 2024). I supervised interns as they researched complex topics, including understanding common oversights regarding <strong><a href="https://arxiv.org/abs/2403.14587" target="_blank">linear forecasting models</a></strong>, which was presented at ICML 2024. I also created <strong><a href="https://dl.acm.org/doi/abs/10.1145/3578356.3592582" target="_blank">FoldFormer</a></strong>, a highly efficient transformer model currently deployed in Huawei's cloud infrastructure for forecasting resource demand.</p>
									</div>

									<div class="project-item" style="margin-top:2em;">
										<h4>PhD Research</h4>
										<p>
											My PhD thesis at the University of Edinburgh, titled "Learning reliable representations when proxy objectives fail," investigated why deep neural networks often learn unreliable or non-robust solutions. This happens when a model trained on a substitute (proxy) task learns 'shortcuts' based on easy-to-compute features (e.g., background color) instead of the complex features (e.g., object shape) needed for true generalization. I distilled this core problem into a talk, 'The Tale of the Lazy Learning Machine,' for the University of Edinburgh's Three Minute Thesis (3MT) competition, where I competed at the university-wide level.
										</p>
										
										<span class="image fit"><img src="images/3MT.jpg" alt="Slide from the Three Minute Thesis competition, titled The Tale of The Lazy Learning Machine." /></span>
										
										<p style="margin-top: 1.5em;">
											My thesis introduced three novel methods to mitigate this problem:
										</p>
										<ul>
											<li><strong>Deep Decision Tree Layer (DDTL):</strong> A method for semantic hashing that prevents over-compression by composing hash codes from both supervised (class-based) and unsupervised (contrastive) parts, ensuring an efficient and well-distributed use of the available hash space.</li>
											<li><strong><a href="https://arxiv.org/abs/2003.08821" target="_blank">Deep Hierarchical Object Grouping (DHOG)</a>:</strong> An approach that improves deep clustering by forcing a network to find a diverse hierarchy of solutions, preventing it from settling on a single, simple grouping based on trivial features.</li>
											<li><strong><a href="https://arxiv.org/abs/2011.11486" target="_blank">Latent Adversarial Debiasing (LAD)</a>:</strong> A technique that removes spurious correlations from training data. It uses a VQ-VAE to access the data manifold and performs an adversarial walk in the latent space to generate new, de-biased training images.</li>
										</ul>
										<p>
											During my PhD, I also developed GINN (Geometric Illustration of Neural Networks), an interactive tool to build intuition for how neural networks function.
										</p>
										<a href="https://www.bayeswatch.com/assets/ginn/good3.html" target="_blank" class="button">Interactive NN Demo</a>
										<a href="assets/Learning%20reliable%20representations%20when%20proxy%20objectives%20fail%20-%20Luke%20Darlow%20PhD%20Thesis.pdf" class="button alt">Read Full Thesis</a>
									</div>

									<div class="project-item" style="margin-top:2em;">
										<h4>Biometrics & Subsurface Fingerprint Analysis</h4>
										<p>My early research at CSIR in South Africa involved pioneering work in biometrics. I designed computer vision models to extract features from fingerprints and developed novel algorithms to extract usable subsurface fingerprints from 3D Optical Coherence Tomography (OCT) scans in real-time. This work led to <span>10 publications in the span two years</span>, tangible physical and digital outputs that were presented to high-level dignitaries including the the minister of science and technology of South Africa, and several awards, including a 'best poster award' (shown below) at the top biometrics conference, ICB, in 2016.</p>
										<span class="image fit"><a href="assets/Luke Darlow Poster ICB2016.pdf" target="_blank"><img src="images/poster.png" alt="ICB Poster." /></span>
									</div>

									<div class="project-item" style="margin-top:2em;">
										<h4>Publications</h4>
										<p>A complete list of my publications can be found on my Google Scholar profile.</p>
										<a href="https://scholar.google.com/citations?user=qxgq8n8AAAAJ" class="button">View on Google Scholar</a>
									</div>
								</div>
							</section>

						<!-- Four -->
							<section id="four">
								<div class="container">
									<h3>Contact</h3>
									<p>I am always open to discussing new ideas, collaborations, or interesting opportunities. Please feel free to reach out on X or LinkedIn</p>
								</div>
							</section>



					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>